# Recognising Hand Gesture Recognition Using Deep Learning

## Overview

This project focuses on building a hand gesture recognition system using Convolutional Neural Networks (CNNs) and the MediaPipe library. The goal of the project is to enable users to play the game "Rock, Paper, Scissors" using hand gestures captured through their webcam. The model employed in this project is a variation of the VGG16 CNN architecture, which has been trained on a dataset of hand gesture images obtained from Kaggle.

## Table of Contents

- [Dataset](#dataset)
- [Model Architecture](#model-architecture)

## Dataset
The dataset used for training the hand gesture recognition model was obtained from Kaggle HaGRID Sample 30k 384p(Source)[https://www.kaggle.com/datasets/innominate817/hagrid-sample-30k-384p]. It consists of a variety of hand gestures. 

## Model Architecture
The Convolutional Neural Network (CNN) model used in this project is a variation of the VGG16 architecture. It consists of several convolutional layers, followed by fully connected layers. The model has been trained to classify hand gestures into the "Rock," "Paper," and "Scissors" classes.
